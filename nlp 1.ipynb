{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multi_rake import Rake\n",
    "\n",
    "text_en = (\n",
    "    'Compatibility of systems of linear constraints over the set of '\n",
    "    'natural numbers. Criteria of compatibility of a system of linear '\n",
    "    'Diophantine equations, strict inequations, and nonstrict inequations '\n",
    "    'are considered. Upper bounds for components of a minimal set of '\n",
    "    'solutions and algorithms of construction of minimal generating sets '\n",
    "    'of solutions for all types of systems are given. These criteria and '\n",
    "    'the corresponding algorithms for constructing a minimal supporting '\n",
    "    'set of solutions can be used in solving all the considered types of '\n",
    "    'systems and systems of mixed types.'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('minimal generating sets', 8.666666666666666), ('linear diophantine equations', 8.5), ('minimal supporting set', 7.666666666666666), ('minimal set', 4.666666666666666), ('linear constraints', 4.5), ('natural numbers', 4.0), ('strict inequations', 4.0), ('nonstrict inequations', 4.0), ('upper bounds', 4.0), ('mixed types', 3.666666666666667)]\n"
     ]
    }
   ],
   "source": [
    "rake = Rake()\n",
    "\n",
    "keywords = rake.apply(text_en)\n",
    "\n",
    "print(keywords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lines', 'string', 'words']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "lines = 'lines is some string of words'\n",
    "tokenized = nltk.word_tokenize(lines)\n",
    "nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if(pos[:2] == 'NN')]\n",
    "print (nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for data\n",
    "import pandas as pd\n",
    "import collections\n",
    "import json## for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wordcloud## for text processing\n",
    "import re\n",
    "import nltk## for language detection\n",
    "import langdetect ## for sentiment\n",
    "from textblob import TextBlob## for ner\n",
    "import spacy## for vectorizer\n",
    "from sklearn import feature_extraction, manifold## for word embedding\n",
    "import gensim.downloader as gensim_api## for topic modeling\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'CRIME',\n",
       " 'headline': 'There Were 2 Mass Shootings In Texas Last Week, But Only 1 On TV',\n",
       " 'authors': 'Melissa Jeltsen',\n",
       " 'link': 'https://www.huffingtonpost.com/entry/texas-amanda-painter-mass-shooting_us_5b081ab4e4b0802d69caad89',\n",
       " 'short_description': 'She left her husband. He killed their children. Just another day in America.',\n",
       " 'date': '2018-05-26'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_dics = []\n",
    "with open('data.json', mode='r', errors='ignore') as json_file:\n",
    "    for dic in json_file:\n",
    "        lst_dics.append( json.loads(dic) )## print the first one      \n",
    "lst_dics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
